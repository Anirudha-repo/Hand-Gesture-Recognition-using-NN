# Hand Gesture Recognition using Neural Networks

This project focuses on recognizing hand gestures using neural networks.

The **Dataset** consists of a total of 5243 hand gesture images which were further sub divided into **9** classes: call_me, fingers_crossed, okay, paper, peace, rock, rock_on, scissor, thumbs up.

 The project involves:

- **Data Collection**: Gathering a dataset of hand gesture images from sources like public datasets or manually collecting images. Ensuring a balanced dataset with various hand gestures.
- **Data Preprocessing**: Cleaning and preparing the images for training by resizing them to a uniform size, normalizing pixel values, and augmenting the data to increase diversity.
- **Model Architecture**: Designing a neural network model with Convolutional Neural Networks (CNNs) for feature extraction and Dense layers for classification. Experimenting with different architectures to optimize performance.
- **Training**: Training the model on the preprocessed dataset, adjusting hyperparameters such as learning rate, batch size, and number of epochs to optimize performance.
- **Evaluation**: Assessing the model's accuracy using metrics like confusion matrix and classification report. Performing cross-validation to ensure the model's robustness.
- **Deployment**: Implementing the trained model in a real-time application to recognize hand gestures from live video feeds. Integrating the model with a user interface for practical use.

It has a **training accuracy** of 94.90% and **testing accuracy** of 80.08%.

This project leverages neural networks to create an efficient and accurate hand gesture recognition system.
